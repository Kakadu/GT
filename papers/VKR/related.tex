\section{Related Works}

As our work makes use of both functional (combinators) and object-oriented (classes and objects) features of \textsc{OCaml} there are some relevant works
in both domains of typeful functional and object-oriented programming. The most relevant framework, developed for \textsc{OCaml}, which utilises the same
ideas, but makes essentially different design decisions, is \textsc{Visitors}~\cite{Visitors}; we postpone the in-depth comparison of our framework with
\textsc{Visitors} until the end of this section.

First, there is a number of frameworks for generic programming in \textsc{OCaml}, which utilise a completely generative approach~\cite{Yallop,PPXLib}~---
all requested generic functions for all types are generated by the framework separately. This approach is very practical as long as the assortment
of shipped functions is rich enough and sufficient for a given use case. However, if not, someone has to extend the framework, implementing
all missing functions anew (and, potentially, with a very little code reuse). In addition, the functions themselves are hard coded and
lack extensibility. With our framework, first, many end-user generic functions can be easily derived from the generated ones, and second, in order to
implement a completely fresh plugin it is sufficient to hard code only ``the interesting'' part, as the generation of the single traversal
function and transformation class are already provided by the framework itself.

A number of approaches to functional generic programming utilises the idea of type \emph{representation}~\cite{Hinze}.
The idea is to develop a uniform representation for any type under transformation and provide two conversion functions from- and to this representation
(ideally, comprising an isomorphism). A generic function performs transformation on a representation of actual data structure, which makes it possible to
implement every such function only once. The conversion functions themselves can in turn be constructed (semi) automatically using such features of
the language type system as type classes~\cite{Hinze,ALaCarte} or type families~\cite{InstantGenerics} (in \textsc{Haskell}) or generated using syntax extension
mechanism~\cite{GenericOCaml} (in \textsc{OCaml}). While some of these approaches allow extension and modification of generic functions by, for example, specifying a
specific treatment for some types or supporting extensible types, our solution is still more flexible as it allows modification with granularity of individual
constructors. In addition, with our framework it is possible for multiple versions of the same generic function for the same type to coexist.

A different approach is taken in ``Scrap Your Boilerplate'', or SYB~\cite{SYB}, initially developed for \textsc{Haskell}. This approach makes it
possible to implement transformations which identify the occurrences of instances of a certain datatype inside arbitrary data structure. Two main
kinds of transformations are supported: \emph{queries}, which collect and return the instances of the designated datatype based on some user-defined
criterion, and \emph{transformations}, which uniformly propagate some type-preserving transformation for a datatype of interest. In the follow-up papers
the approach was extended to deal with transformations which traverse pairs of data structures~\cite{SYB1} and to support the extension of already implemented
transformations with new type cases~\cite{SYB2}. Later the approach was implemented  for other languages, including \textsc{OCaml}~\cite{SYBOCaml,Staged}.
Unlike our case, SYB takes the route of discriminating on a whole type, not individual constructors. In addition the shape of available transformations look rather
restrictive, and, once implemented, transformations for a given type can not be modified. It is interesting, that, potentially, SYB-style generic functions
can ``break through the encapsulation barrier''~--- indeed, they can identify the occurrences of values of type of interest inside \emph{arbitrarily typed}
data structures. Thus, their behaviour depend on the actual details of data structure organisation, including those which were intentionally hidden by encapsulation.
This may result in, first, the possibility for undesirable reverse-engineering (by applying various type-sensitive transformations and analysing the results) and,
second, in fragility of interfaces~--- after a modification of data structure implementation generic functions for \emph{old} version can still be applied with
neither static nor dynamic error, but with wrong (or undesirable) results. 

There is a certain similarity between our approach and \emph{object algebras}~\cite{ObjectAlgebras}. Object algebras were proposed as a solution
for expression problem in mainstream object-oriented languages (\textsc{Java}, \textsc{C++}, \textsc{C\#}), which would not require advanced type system features besides
regular inheritance and generics. In the original exposition object algebras were presented as a design and implementation pattern; the follow-up
works have improved the initial proposal in various directions~\cite{ObjectAlgebrasAttribute,ObjectAlgebrasSYB}.
With object algebras a data structure under transformation is also encoded using the method-per-variant (constructor) idea, which makes it possible to
provide the extensibility in both dimensions and retroactive implementation. However, being developed for essentially different language environment,
the solution using object algebras would differ from ours in many concrete aspects. First, with object algebras the ``shape'' of a data structure has to
be represented by a generic function, which takes a concrete object algebra instance as a parameter (``Church encoding'' for types~\cite{Hinze}). Applying
this function to various implementations of object algebra one can acquire various transformations (for example, printing). To instantiate the data
structure itself one needs to provide a specific object algebra instance~--- \emph{factory}. However, after the instantiation the data structure itself
can not be generically transformed anymore. Thus, object algebras force end users to switch to data-as-function representation, which may or may not be
beneficial in different concrete cases. In contrast our approach non-destructively adds new functionality to the familiar world of algebraic data types,
pattern matching and recursive functions. Generic transformation implementations are completely separated from data representation, and end users may
freely transform their data structures in a familiar way without losing the ability to apply (or extend) generic functions. Another difference stems
from the fact that in our case, unlike mainstream object-oriented languages, polymorphic variants are used as a main tool for datatype extension.
Supporting polymorphic variants as a mean for datatype extensibility requires a fresh solution.

Finally, among existing generic programming frameworks for \textsc{OCaml} we can name two, which resemble ours: \cd{ppx\_deriving}/\cd{ppx\_traverse}
(a part of \cd{ppxlib}~\cite{PPXLib}) and \textsc{Visitors}~\cite{Visitors}.

\cd{ppx\_deriving} is the simplest approach possible: type declarations are mapped one-to-one to recursive functions representing a specific kind of
transformation. It is the most efficient implementation (functions are called directly, no late biding involved) but it is not extensible. If end users
need to modify slightly the generated function, they should copy and paste generated code to modify it manually. The amount of work to support a new
transformation will drastically increase if type definitions change during the development cycle.

In \cd{ppx\_traverse} extensible transformations are represented as objects; unlike our case, method-per-type approach is used. In addition 
\cd{ppx\_traverse} does not make use of inherited attributes, thus some transformations like equality or comparison are not representable.

\textsc{Visitors}, on the other hand, explores a similar to ours object-oriented approach, in which many decisions, rejected by us, were taken (and vice versa). Here
we summarise the main differences:

\begin{itemize}
   \item \textsc{Visitors} is excessively object-oriented~--- in order to use it one needs to instantiate some object and call proper method. In our case as long as
     only predefined features are required one can use a more native combinatorial interface.
     
   \item \textsc{Visitors} implements a number of useful transformations in an \emph{ad-hoc} manner; in our case all transformations are instances of the
     same generic scheme. It is possible to combine different transformations via inheritance as long as the types of underlying scheme unify. We also argue, that
     in our framework the implementation of user-defined plugins is much easier.
     
   \item Following SYB, \textsc{Visitors} takes a type-discriminating route: for each type of interest (including the built-in ones) there is a dedicated
     transformation method in each object, representing a transformation. While this solution indeed adds some flexibility, we firmly oppose it, since it
     breaks the encapsulation: inspecting the methods of a transformation (which cannot be hidden in a module signature) one can retrieve some
     information about the implementation of encapsulated types. Even worse, the data structures of abstract types can be manipulated in an unprescribed
     manner using the public type-transforming interface.

   \item In our case the type parameters for transformation classes have to be specified by an end user. With \textsc{Visitors} this burden is offloaded to the
     compiler with the aid of some neat trick. However, this trick makes it impossible to use \textsc{Visitors} syntax extension in module signatures. There is no
     such problem in our case~--- our framework can be equally used in both implementation and interface files.

   \item \textsc{Visitors} in its current state\footnote{The latest available version is 20180513} does not support polymorphic variants.
   
   \item \textsc{GT} supports arbitrary type constructor applications but \textsc{Visitors} in its current state doesn't (both in monomorphic and polymorphic mode).
     For instance, the following example doesn't compile:
     
   \begin{lstlisting}
      type ('a,'b) alist = Nil | Cons of 'a * 'b
      [@@deriving visitors { variety = "map"; polymorphic = true }]

      type 'a list = ('a, 'a list) alist
      [@@deriving visitors { variety = "map"; polymorphic = false }]
   \end{lstlisting}
   
   Moreover, adding an extra construct doesn't solve the problem:
   
    \begin{lstlisting}
       type 'a list = L of ('a, 'a list) alist [@@unboxed]
       [@@deriving visitors { variety = "map"; polymorphic = false }]
    \end{lstlisting}
    
    There is also an issue with type aliases in polymorphic mode (monomorphic part of \textsc{Visitors} compiles successfully):
    
    \begin{lstlisting}
       type ('a,'b) t = Foo of 'a * 'b (* OK *)
       [@@deriving visitors { variety = "map"; polymorphic = true }]
       
       type 'a t2 = ('a, int) t
       [@@deriving visitors { variety = "map"; name="yyy"; polymorphic = true }]
    \end{lstlisting}
    
    The generated code can be fixed manually by removing explicit polymorphic type annotations from objects' methods, which leads to the code
    very similar to the one generated by \textsc{GT}. From these we can conclude that \textsc{GT} can be seen an a reimplementation of polymorphic
    mode of \textsc{Visitors} where more type declarations compile successfully.
    
\end{itemize}
